Broadly, transformer models can be grouped into three categories:-
1. GPT-like (also called auto-regressive Transformer models)
2. BERT-like (also called auto-encoding Transformer models)
3. BART/T5-like (also called sequence-to-sequence Transformer models)

# References
1. https://huggingface.co/learn/nlp-course/chapter1/1